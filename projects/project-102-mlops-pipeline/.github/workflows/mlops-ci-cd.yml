name: MLOps CI/CD Pipeline

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main ]

env:
  PYTHON_VERSION: '3.11'
  MLFLOW_TRACKING_URI: ${{ secrets.MLFLOW_TRACKING_URI }}

jobs:
  lint-and-test:
    name: Lint and Test
    runs-on: ubuntu-latest

    steps:
    - name: Checkout code
      uses: actions/checkout@v3

    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}
        cache: 'pip'

    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt -r requirements-dev.txt

    - name: Lint with flake8
      run: |
        flake8 src tests --count --select=E9,F63,F7,F82 --show-source --statistics
        flake8 src tests --count --max-complexity=10 --max-line-length=127 --statistics

    - name: Format check with black
      run: |
        black --check src tests

    - name: Type check with mypy
      run: |
        mypy src
      continue-on-error: true

    - name: Run unit tests
      run: |
        pytest tests/unit -v --cov=src --cov-report=xml --cov-report=term

    - name: Upload coverage to Codecov
      uses: codecov/codecov-action@v3
      with:
        file: ./coverage.xml
        flags: unittests
        name: codecov-umbrella

  integration-test:
    name: Integration Tests
    runs-on: ubuntu-latest
    needs: lint-and-test

    services:
      postgres:
        image: postgres:14
        env:
          POSTGRES_USER: mlflow
          POSTGRES_PASSWORD: mlflow
          POSTGRES_DB: mlflow
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 5432:5432

      redis:
        image: redis:7
        options: >-
          --health-cmd "redis-cli ping"
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 6379:6379

    steps:
    - name: Checkout code
      uses: actions/checkout@v3

    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}
        cache: 'pip'

    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt -r requirements-dev.txt

    - name: Run integration tests
      run: |
        pytest tests/integration -v
      env:
        POSTGRES_HOST: localhost
        POSTGRES_PORT: 5432
        REDIS_HOST: localhost
        REDIS_PORT: 6379

  dvc-pipeline:
    name: DVC Pipeline Execution
    runs-on: ubuntu-latest
    needs: integration-test
    if: github.event_name == 'push' && github.ref == 'refs/heads/main'

    steps:
    - name: Checkout code
      uses: actions/checkout@v3

    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}

    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install dvc dvc-s3

    - name: Configure DVC
      run: |
        dvc remote modify storage access_key_id ${{ secrets.AWS_ACCESS_KEY_ID }}
        dvc remote modify storage secret_access_key ${{ secrets.AWS_SECRET_ACCESS_KEY }}

    - name: Pull data
      run: |
        dvc pull
      continue-on-error: true

    - name: Run DVC pipeline
      run: |
        dvc repro
      continue-on-error: true

  model-training:
    name: Train and Register Model
    runs-on: ubuntu-latest
    needs: dvc-pipeline
    if: github.event_name == 'push' && github.ref == 'refs/heads/main'

    steps:
    - name: Checkout code
      uses: actions/checkout@v3

    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}

    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt

    - name: Generate synthetic data
      run: |
        python << EOF
        import sys
        sys.path.insert(0, '.')
        from src.data.ingestion import DataIngestor

        ingestor = DataIngestor()
        df = ingestor.generate_synthetic_data(n_samples=1000)
        ingestor.save_data(df, 'ci_test_data.csv', upload_to_s3=False)
        EOF

    - name: Train model
      run: |
        python << EOF
        import sys
        sys.path.insert(0, '.')
        import pandas as pd
        from src.data.preprocessing import DataPreprocessor
        from src.training.trainer import ModelTrainer
        from src.training.evaluator import ModelEvaluator

        # Load and preprocess data
        df = pd.read_csv('data/raw/ci_test_data.csv')
        preprocessor = DataPreprocessor()
        X, y = preprocessor.preprocess(df, is_training=True)
        X_train, X_test, y_train, y_test = preprocessor.split_data(X, y)

        # Train model
        trainer = ModelTrainer()
        model, run_id = trainer.train_model(
            'logistic_regression',
            X_train, y_train,
            X_test, y_test
        )

        # Evaluate
        evaluator = ModelEvaluator()
        metrics = evaluator.evaluate_model(model, X_test, y_test)
        print(f"Model metrics: {metrics}")
        print(f"MLflow run ID: {run_id}")

        # Save run ID for next job
        with open('run_id.txt', 'w') as f:
            f.write(run_id)
        EOF
      env:
        MLFLOW_TRACKING_URI: ${{ secrets.MLFLOW_TRACKING_URI }}
        AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
        AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}

    - name: Upload run ID
      uses: actions/upload-artifact@v3
      with:
        name: run-id
        path: run_id.txt

  model-validation:
    name: Validate Model
    runs-on: ubuntu-latest
    needs: model-training

    steps:
    - name: Checkout code
      uses: actions/checkout@v3

    - name: Download run ID
      uses: actions/download-artifact@v3
      with:
        name: run-id

    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}

    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt

    - name: Validate model performance
      run: |
        RUN_ID=$(cat run_id.txt)
        echo "Validating model from run: $RUN_ID"

        python << EOF
        import sys
        sys.path.insert(0, '.')
        from src.training.registry import ModelRegistry
        import mlflow

        mlflow.set_tracking_uri('${{ secrets.MLFLOW_TRACKING_URI }}')

        run_id = '${RUN_ID}'
        run = mlflow.get_run(run_id)

        # Check metrics
        f1_score = run.data.metrics.get('test_f1', 0)
        accuracy = run.data.metrics.get('test_accuracy', 0)

        print(f"F1 Score: {f1_score}")
        print(f"Accuracy: {accuracy}")

        # Validation thresholds
        if f1_score < 0.6 or accuracy < 0.65:
            print("Model does not meet minimum thresholds")
            sys.exit(1)
        else:
            print("Model validation passed")
        EOF
      env:
        MLFLOW_TRACKING_URI: ${{ secrets.MLFLOW_TRACKING_URI }}

  deploy-staging:
    name: Deploy to Staging
    runs-on: ubuntu-latest
    needs: model-validation
    if: github.event_name == 'push' && github.ref == 'refs/heads/main'

    steps:
    - name: Checkout code
      uses: actions/checkout@v3

    - name: Download run ID
      uses: actions/download-artifact@v3
      with:
        name: run-id

    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}

    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt

    - name: Register and transition to Staging
      run: |
        RUN_ID=$(cat run_id.txt)

        python << EOF
        import sys
        sys.path.insert(0, '.')
        from src.training.registry import ModelRegistry

        registry = ModelRegistry()

        # Register model
        version = registry.register_model(
            run_id='${RUN_ID}',
            tags={'source': 'ci-cd', 'environment': 'staging'}
        )

        # Transition to Staging
        registry.transition_model_stage(
            model_name='churn-classifier',
            version=version,
            stage='Staging'
        )

        print(f"Model version {version} deployed to Staging")
        EOF
      env:
        MLFLOW_TRACKING_URI: ${{ secrets.MLFLOW_TRACKING_URI }}

    - name: Notify deployment
      run: |
        echo "Model deployed to Staging environment"
        # Add Slack/email notification here

  deploy-production:
    name: Deploy to Production
    runs-on: ubuntu-latest
    needs: deploy-staging
    if: github.event_name == 'push' && github.ref == 'refs/heads/main'
    environment:
      name: production
      url: https://mlops.example.com

    steps:
    - name: Checkout code
      uses: actions/checkout@v3

    - name: Manual approval required
      run: |
        echo "Manual approval required for production deployment"
        echo "Promote model in MLflow UI from Staging to Production"

    - name: Notify production deployment
      run: |
        echo "Production deployment completed"
        # Add notification here
